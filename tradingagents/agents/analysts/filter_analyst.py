"""è‚¡ç¥¨æ¦‚å¿µç­›é€‰Agent - ç”¨äºç­›é€‰ç¬¦åˆæ¡ä»¶çš„æ¦‚å¿µè‚¡ç¥¨å¹¶åŠ å…¥åˆ°graphä¸­"""
import json
import pandas as pd
import akshare as ak
import os
from datetime import datetime, timedelta
import time
import warnings
from typing import Dict, Any, List
from tradingagents.utils.logging_manager import get_logger

# å¿½ç•¥è­¦å‘Šä¿¡æ¯
warnings.filterwarnings('ignore')

# åˆå§‹åŒ–æ—¥å¿—
logger = get_logger('agents')

class StockFilterAgent:
    def __init__(self, cache_dir="./stock_cache"):
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
        logger.info(f"ğŸ“Š è‚¡ç¥¨ç­›é€‰Agentåˆå§‹åŒ–ï¼Œç¼“å­˜ç›®å½•: {cache_dir}")
        
    def get_cached_data(self, key: str, data_func, cache_minutes: int = 30) -> pd.DataFrame:
        """ç¼“å­˜æ•°æ®è·å–å‡½æ•°"""
        cache_file = os.path.join(self.cache_dir, f"{key}.pkl")
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœªè¿‡æœŸ
        if os.path.exists(cache_file):
            file_time = datetime.fromtimestamp(os.path.getmtime(cache_file))
            if datetime.now() - file_time < timedelta(minutes=cache_minutes):
                logger.debug(f"ğŸ” ä»ç¼“å­˜åŠ è½½æ•°æ®: {key}")
                return pd.read_pickle(cache_file)
        
        # è·å–æ–°æ•°æ®å¹¶ç¼“å­˜
        logger.debug(f"ğŸ“¥ è·å–æ–°æ•°æ®: {key}")
        data = data_func()
        data.to_pickle(cache_file)
        return data
    
    def get_stock_basic_info(self) -> pd.DataFrame:
        """è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
        def fetch_data():
            # è·å–Aè‚¡åŸºæœ¬ä¿¡æ¯
            logger.info("ğŸ“¥ è·å–Aè‚¡åŸºæœ¬ä¿¡æ¯")
            stock_info = ak.stock_info_a_code_name()
            # è·å–å®æ—¶è¡Œæƒ…æ•°æ®
            logger.info("ğŸ“¥ è·å–Aè‚¡å®æ—¶è¡Œæƒ…æ•°æ®")
            stock_spot = ak.stock_zh_a_spot_em()
            # åˆå¹¶æ•°æ®
            merged_data = pd.merge(stock_info, stock_spot, left_on='code', right_on='ä»£ç ')
            return merged_data
        return self.get_cached_data("stock_basic_info", fetch_data)
    
    def get_financial_indicators(self, stock_codes: List[str]) -> pd.DataFrame:
        """è·å–è´¢åŠ¡æŒ‡æ ‡æ•°æ®"""
        def fetch_data():
            financial_data = {}
            logger.info(f"ğŸ“¥ è·å–{len(stock_codes[:50])}åªè‚¡ç¥¨çš„è´¢åŠ¡æŒ‡æ ‡")
            for code in stock_codes[:50]:  # é™åˆ¶æ•°é‡é¿å…è¯·æ±‚è¿‡å¤š
                try:
                    # è·å–ä¸ªè‚¡è´¢åŠ¡æŒ‡æ ‡
                    indicator = ak.stock_financial_analysis_indicator(symbol=code)
                    if not indicator.empty:
                        financial_data[code] = indicator.iloc[0]  # å–æœ€æ–°æ•°æ®
                    time.sleep(0.1)  # é˜²æ­¢åçˆ¬
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–{code}è´¢åŠ¡æŒ‡æ ‡å¤±è´¥: {str(e)}")
                    continue
            return pd.DataFrame.from_dict(financial_data, orient='index')
        return self.get_cached_data("financial_indicators", fetch_data)
    
    def get_technical_indicators(self, stock_codes: List[str]) -> pd.DataFrame:
        """è·å–æŠ€æœ¯æŒ‡æ ‡æ•°æ®"""
        def fetch_data():
            technical_data = {}
            logger.info(f"ğŸ“¥ è·å–{len(stock_codes[:50])}åªè‚¡ç¥¨çš„æŠ€æœ¯æŒ‡æ ‡")
            for code in stock_codes[:50]:
                try:
                    # è·å–å†å²æ•°æ®è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                    hist_data = ak.stock_zh_a_hist(symbol=code, period="daily", start_date="20240101")
                    if not hist_data.empty:
                        # è®¡ç®—ç®€å•æŠ€æœ¯æŒ‡æ ‡
                        latest = hist_data.iloc[-1]
                        technical_data[code] = {
                            'current_price': latest['æ”¶ç›˜'],
                            'volume_ratio': latest['æˆäº¤é‡'] / hist_data['æˆäº¤é‡'].mean() if hist_data['æˆäº¤é‡'].mean() > 0 else 1,
                            'price_change': (latest['æ”¶ç›˜'] - hist_data.iloc[-2]['æ”¶ç›˜']) / hist_data.iloc[-2]['æ”¶ç›˜'] * 100,
                            'ma5': hist_data['æ”¶ç›˜'].tail(5).mean(),
                            'ma20': hist_data['æ”¶ç›˜'].tail(20).mean()
                        }
                    time.sleep(0.1)
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–{code}æŠ€æœ¯æŒ‡æ ‡å¤±è´¥: {str(e)}")
                    continue
            return pd.DataFrame.from_dict(technical_data, orient='index')
        return self.get_cached_data("technical_indicators", fetch_data)
    
    def filter_stocks_by_technical(self, stock_names: List[str], concept_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åŸºäºæŠ€æœ¯æŒ‡æ ‡ç­›é€‰è‚¡ç¥¨"""
        logger.info("ğŸ” å¼€å§‹æŠ€æœ¯æŒ‡æ ‡ç­›é€‰...")
        
        # è·å–æ‰€æœ‰è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        all_stocks = self.get_stock_basic_info()
        
        # å°†è‚¡ç¥¨åç§°æ˜ å°„åˆ°ä»£ç 
        name_to_code = {}
        valid_stocks = []
        
        for stock_name in stock_names:
            matches = all_stocks[all_stocks['name'] == stock_name]
            if not matches.empty:
                code = matches.iloc[0]['code']
                name_to_code[stock_name] = code
                valid_stocks.append(code)
        
        if not valid_stocks:
            logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç ")
            return []
        
        # è·å–æŠ€æœ¯æŒ‡æ ‡
        technical_data = self.get_technical_indicators(valid_stocks)
        
        # ç­›é€‰æ¡ä»¶
        filtered_stocks = []
        for stock_name, stock_code in name_to_code.items():
            if stock_code in technical_data.index:
                tech_data = technical_data.loc[stock_code]
                
                # æŠ€æœ¯ç­›é€‰æ¡ä»¶
                conditions = [
                    tech_data.get('price_change', 0) < 5,  # å½“æ—¥æ¶¨å¹…å°äº5%
                    tech_data.get('volume_ratio', 0) > 0.8,  # é‡æ¯”å¤§äº0.8
                    tech_data.get('current_price', 0) > tech_data.get('ma5', 0),  # è‚¡ä»·åœ¨5æ—¥å‡çº¿ä¸Š
                    tech_data.get('current_price', 0) > 5,  # è‚¡ä»·é«˜äº5å…ƒ
                ]
                
                if sum(conditions) >= 3:  # æ»¡è¶³è‡³å°‘3ä¸ªæ¡ä»¶
                    filtered_stocks.append({
                        'è‚¡ç¥¨åç§°': stock_name,
                        'è‚¡ç¥¨ä»£ç ': stock_code,
                        'å½“å‰ä»·æ ¼': tech_data.get('current_price', 0),
                        'æ¶¨è·Œå¹…': tech_data.get('price_change', 0),
                        'é‡æ¯”': tech_data.get('volume_ratio', 0),
                        'æ¦‚å¿µåç§°': concept_data['æ¦‚å¿µåç§°'],
                        'æ¦‚å¿µæ’å': concept_data['æ’å']
                    })
        
        logger.info(f"âœ… æŠ€æœ¯æŒ‡æ ‡ç­›é€‰å®Œæˆï¼Œæ‰¾åˆ°{len(filtered_stocks)}åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
        return filtered_stocks
    
    def filter_stocks_by_financial(self, stock_names: List[str]) -> List[str]:
        """åŸºäºè´¢åŠ¡æŒ‡æ ‡ç­›é€‰è‚¡ç¥¨"""
        logger.info("ğŸ” å¼€å§‹è´¢åŠ¡æŒ‡æ ‡ç­›é€‰...")
        
        all_stocks = self.get_stock_basic_info()
        name_to_code = {}
        valid_stocks = []
        
        for stock_name in stock_names:
            matches = all_stocks[all_stocks['name'] == stock_name]
            if not matches.empty:
                code = matches.iloc[0]['code']
                name_to_code[stock_name] = code
                valid_stocks.append(code)
        
        if not valid_stocks:
            logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç ")
            return []
        
        # è·å–è´¢åŠ¡æŒ‡æ ‡
        financial_data = self.get_financial_indicators(valid_stocks)
        
        filtered_stocks = []
        for stock_name, stock_code in name_to_code.items():
            if stock_code in financial_data.index:
                fin_data = financial_data.loc[stock_code]
                
                # è´¢åŠ¡ç­›é€‰æ¡ä»¶
                try:
                    pe_ratio = fin_data.get('å¸‚ç›ˆç‡', 1000)
                    pb_ratio = fin_data.get('å¸‚å‡€ç‡', 1000)
                    roe = fin_data.get('å‡€èµ„äº§æ”¶ç›Šç‡', 0)
                    
                    conditions = [
                        pe_ratio > 0 and pe_ratio < 50,  # å¸‚ç›ˆç‡åœ¨0-50ä¹‹é—´
                        pb_ratio > 0 and pb_ratio < 5,   # å¸‚å‡€ç‡åœ¨0-5ä¹‹é—´
                        roe > 5  # å‡€èµ„äº§æ”¶ç›Šç‡å¤§äº5%
                    ]
                    
                    if sum(conditions) >= 2:  # æ»¡è¶³è‡³å°‘2ä¸ªæ¡ä»¶
                        filtered_stocks.append(stock_name)
                except Exception as e:
                    logger.warning(f"âš ï¸ å¤„ç†{stock_name}è´¢åŠ¡æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                    continue
        
        logger.info(f"âœ… è´¢åŠ¡æŒ‡æ ‡ç­›é€‰å®Œæˆï¼Œæ‰¾åˆ°{len(filtered_stocks)}åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
        return filtered_stocks
    
    def comprehensive_filter(self, concept_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç»¼åˆç­›é€‰è‚¡ç¥¨"""
        stock_names = concept_data['æˆåˆ†è‚¡åç§°']
        logger.info(f"ğŸ” å¼€å§‹ç­›é€‰æ¦‚å¿µ '{concept_data['æ¦‚å¿µåç§°']}' ä¸‹çš„ {len(stock_names)} åªè‚¡ç¥¨...")
        
        # ç¬¬ä¸€è½®ï¼šæŠ€æœ¯æŒ‡æ ‡ç­›é€‰
        technically_filtered = self.filter_stocks_by_technical(stock_names, concept_data)
        
        if not technically_filtered:
            logger.warning(f"âš ï¸ æ¦‚å¿µ '{concept_data['æ¦‚å¿µåç§°']}' ä¸‹æ²¡æœ‰é€šè¿‡æŠ€æœ¯æŒ‡æ ‡ç­›é€‰çš„è‚¡ç¥¨")
            return []
        
        # ç¬¬äºŒè½®ï¼šè´¢åŠ¡æŒ‡æ ‡ç­›é€‰
        financially_filtered = self.filter_stocks_by_financial(stock_names)
        
        # ç»¼åˆç­›é€‰ç»“æœ
        final_stocks = []
        for stock in technically_filtered:
            if stock['è‚¡ç¥¨åç§°'] in financially_filtered or not financially_filtered:
                final_stocks.append(stock)
        
        # æŒ‰æ¶¨è·Œå¹…æ’åºï¼Œå–å‰5åª
        final_stocks.sort(key=lambda x: abs(x['æ¶¨è·Œå¹…']), reverse=True)
        result = final_stocks[:5]
        
        logger.info(f"âœ… æ¦‚å¿µ '{concept_data['æ¦‚å¿µåç§°']}' ç­›é€‰å®Œæˆï¼Œæ¨è{len(result)}åªè‚¡ç¥¨")
        return result


def concept_stock_filter_agent(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ¦‚å¿µè‚¡ç¥¨ç­›é€‰AgentèŠ‚ç‚¹ï¼Œç”¨äºGraphæµç¨‹
    
    Args:
        state: åŒ…å«ä»¥ä¸‹é”®çš„å­—å…¸:
            - concept_file: æ¦‚å¿µæ•°æ®æ–‡ä»¶è·¯å¾„
            - cache_dir: ç¼“å­˜ç›®å½•è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            - trade_date: äº¤æ˜“æ—¥æœŸï¼ˆå¯é€‰ï¼‰
    
    Returns:
        æ›´æ–°åçš„stateï¼ŒåŒ…å«ç­›é€‰ç»“æœ
    """
    logger.info("ğŸ“Š ===== æ¦‚å¿µè‚¡ç¥¨ç­›é€‰Agentå¼€å§‹æ‰§è¡Œ =====")
    
    # ä»stateä¸­è·å–å‚æ•°
    concept_file = state.get('concept_file', "concept_stocks_recommendation.json")
    cache_dir = state.get('cache_dir', "./stock_cache")
    
    # éªŒè¯æ¦‚å¿µæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(concept_file):
        logger.error(f"âŒ æ¦‚å¿µæ–‡ä»¶ä¸å­˜åœ¨: {concept_file}")
        state['stock_filter_result'] = None
        state['filter_status'] = 'failed'
        state['filter_error'] = f"æ¦‚å¿µæ–‡ä»¶ä¸å­˜åœ¨: {concept_file}"
        return state
    
    try:
        # åˆå§‹åŒ–ç­›é€‰å™¨
        filter_agent = StockFilterAgent(cache_dir=cache_dir)
        
        # åŠ è½½æ¦‚å¿µæ•°æ®
        logger.info(f"ğŸ“¥ åŠ è½½æ¦‚å¿µæ•°æ®: {concept_file}")
        with open(concept_file, 'r', encoding='utf-8') as f:
            concept_data = json.load(f)
        
        # æ‰§è¡Œç­›é€‰
        all_recommendations = []
        logger.info(f"ğŸ“‹ å¼€å§‹å¤„ç† {concept_data['æ¨èæ¦‚å¿µæ€»æ•°']} ä¸ªæ¨èæ¦‚å¿µ...")
        
        for concept in concept_data['æ¨èåˆ—è¡¨']:
            logger.info(f"\nğŸ“Œ å¤„ç†æ¦‚å¿µ: {concept['æ¦‚å¿µåç§°']} (æ’å: {concept['æ’å']})")
            
            try:
                filtered_stocks = filter_agent.comprehensive_filter(concept)
                
                if filtered_stocks:
                    concept_recommendation = {
                        'æ¦‚å¿µåç§°': concept['æ¦‚å¿µåç§°'],
                        'æ¦‚å¿µæ’å': concept['æ’å'],
                        'æ¶¨è·Œå¹…': concept.get('æ¶¨è·Œå¹…(%)', 0),
                        'æ¨èè‚¡ç¥¨': filtered_stocks
                    }
                    all_recommendations.append(concept_recommendation)
                    
                    logger.info(f"ğŸ“ˆ æ¨è {len(filtered_stocks)} åªè‚¡ç¥¨")
                else:
                    logger.info(f"ğŸ“‰ è¯¥æ¦‚å¿µä¸‹æ— ç¬¦åˆç­›é€‰æ¡ä»¶çš„è‚¡ç¥¨")
                    
            except Exception as e:
                logger.error(f"âŒ å¤„ç†æ¦‚å¿µ {concept['æ¦‚å¿µåç§°']} æ—¶å‡ºé”™: {str(e)}")
                continue
        
        # ä¿å­˜ç»“æœåˆ°state
        state['stock_filter_result'] = {
            "ç”Ÿæˆæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "æ¨èæ¦‚å¿µæ•°é‡": len(all_recommendations),
            "æ¨èè¯¦æƒ…": all_recommendations
        }
        state['filter_status'] = 'success'
        
        # å¦‚æœéœ€è¦ï¼Œä¿å­˜åˆ°æ–‡ä»¶
        if state.get('save_filter_result', True):
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"stock_recommendations_{timestamp}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(state['stock_filter_result'], f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ’¾ æ¨èç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            state['filter_output_file'] = output_file
        
        logger.info("ğŸ“Š ===== æ¦‚å¿µè‚¡ç¥¨ç­›é€‰Agentæ‰§è¡Œå®Œæˆ =====")
        return state
        
    except Exception as e:
        logger.error(f"âŒ æ¦‚å¿µè‚¡ç¥¨ç­›é€‰Agentæ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
        state['stock_filter_result'] = None
        state['filter_status'] = 'failed'
        state['filter_error'] = str(e)
        return state


"""
# å°†Agentæ·»åŠ åˆ°Graphçš„ç¤ºä¾‹ä»£ç 
if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šåˆ›å»ºä¸€ä¸ªç®€å•çš„Graphå¹¶æ·»åŠ æ­¤Agent
    from langgraph.graph import Graph, END
    
    # åˆå§‹åŒ–å›¾
    workflow = Graph()
    
    # æ·»åŠ ç­›é€‰AgentèŠ‚ç‚¹
    workflow.add_node("filter_stocks", concept_stock_filter_agent)
    
    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("filter_stocks")
    
    # è®¾ç½®å‡ºå£ç‚¹
    workflow.add_edge("filter_stocks", END)
    
    # ç¼–è¯‘å›¾
    app = workflow.compile()
    
    # æµ‹è¯•è¿è¡Œ
    test_state = {
        "concept_file": "concept_stocks_recommendation_20251013_004800.json",  # æ›¿æ¢ä¸ºå®é™…æ–‡ä»¶è·¯å¾„
        "cache_dir": "./stock_cache",
        "save_filter_result": True
    }
    
    result = app.invoke(test_state)
    
    if result['filter_status'] == 'success':
        logger.info(f"ğŸ‰ ç­›é€‰æˆåŠŸï¼Œå…±æ¨è {result['stock_filter_result']['æ¨èæ¦‚å¿µæ•°é‡']} ä¸ªæ¦‚å¿µ")
    else:
        logger.error(f"âŒ ç­›é€‰å¤±è´¥: {result['filter_error']}")
"""